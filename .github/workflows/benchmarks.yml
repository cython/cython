name: Benchmarks

on:
  workflow_dispatch:
  push:
    paths:
      # Only run on changes likely to affect benchmark code generation
      - ".github/workflows/benchmarks.yml"
      - "Demos/benchmarks/**"
      - "Cython/Utility/**"
      - "Cython/Compiler/Nodes.py"
      - "Cython/Compiler/ExprNodes.py"
      - "Cython/Compiler/Optimize.py"
  pull_request:
    paths:
      # Only run on PRs likely to affect benchmark code generation
      - ".github/workflows/benchmarks.yml"
      - "Demos/benchmarks/**"
      - "Cython/Utility/**"
      - "Cython/Compiler/Nodes.py"
      - "Cython/Compiler/ExprNodes.py"
      - "Cython/Compiler/Optimize.py"
  label:
    # Accepted labels (in the 'if' condition below) are:
    # * benchmark (explicit)
    # * performance (implicit)
    types: [created]


permissions:
  contents: read # to fetch code (actions/checkout)

jobs:
  benchmarks:
    runs-on: ubuntu-latest

    if: |
      ${{ github.event_name != 'label' }} ||
      ${{ github.event.label.name == 'benchmark' }} ||
      ${{ github.event.label.name == 'performance' }} ||

    env:
      CCACHE_SLOPPINESS: "pch_defines,time_macros"
      CCACHE_COMPRESS: 1
      CCACHE_COMPRESSLEVEL: 5
      CCACHE_NOHASHDIR: 1
      CFLAGS: -O3 -g1 -fPIC -mtune=generic

    steps:
      - name: Checkout repo
        uses: actions/checkout@v6
        with:
          fetch-depth: 0
          fetch-tags: true

      - name: Compilation Cache
        uses: hendrikmuhs/ccache-action@v1.2.20
        with:
          create-symlink: true
          variant: ${{ startsWith(runner.os, 'Windows') && 'sccache' || 'ccache' }}  # fake ternary
          save: ${{ startsWith(github.ref, '/refs/pull/') && 'false' || 'true' }}  # fake ternary
          key: ${{ runner.os }}-${{ runner.arch }}-hendrikmuhs-ccache-benchmarks
          max-size: 250M

      - name: Setup python
        uses: actions/setup-python@v6.1.0
        with:
          # List special Pythons first to keep the 'normal' one as (last) "python3.xy".
          python-version: |
            3.14t
            3.10
            3.12
            3.13
            3.14

      - name: Run Benchmarks
        run: |
          # Run benchmarks in all Python versions, Limited C-API only in 3.14.
          LIMITED_API=--with-limited
          for PYTHON in  python3.14  python3.13  python3.14t  python3.12  python3.10  ; do
              ${PYTHON} -m pip install setuptools numpy
              if [[ ${PYTHON} == *t || ${PYTHON} == *"t-dev" ]]; then
                COMMITS=("origin/3.1.x" "origin/master"  "HEAD")
                CYTHONIZE_ARGS="-Xfreethreading_compatible=True"
              else
                COMMITS=("origin/3.0.x"  "3a7a936e099df468dcaa01829ae6567c577489c0"  "${LIMITED_API}" "origin/master"  "${LIMITED_API}" "HEAD")
                CYTHONIZE_ARGS=
              fi
              ${PYTHON} Demos/benchmarks/run_benchmarks.py  --report-size benchmark_sizes_${PYTHON}.csv --report benchmark_results_${PYTHON}.csv --with-python  ${CYTHONIZE_ARGS} ${COMMITS[*]}
              LIMITED_API=
          done | tee benchmarks.log

      - name: Create summary
        run: |
          { echo "## Benchmark results:";
            echo; python Demos/benchmarks/report.py -t timings benchmark_results_*.csv;
            echo; echo "## Benchmark module sizes:";
            echo; python Demos/benchmarks/report.py -t sizes benchmark_sizes_*.csv;
          } >> $GITHUB_STEP_SUMMARY

      - name: Upload results
        uses: actions/upload-artifact@v5
        with:
          name: benchmark_results.txt
          path: benchmarks.log
